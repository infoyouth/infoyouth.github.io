---
title: "11. Goroutines and Concurrency"
description: "üöÄ Unlock the power of concurrency in your Go programs! Learn about goroutines, scheduling, and avoiding race conditions with WaitGroups and best practices. üßµ"
author: infoyouth
date: 2025-11-07 02:00:00 +0000
categories:
  - Programming
  - Go
  - Concurrency
  - Goroutines
  - Scheduling
  - WaitGroups
  - Race Conditions
tags:
  - "Goroutines"
  - "Concurrency"
  - "Go Programming"
  - "Parallel Processing"
  - "WaitGroup"
pin: true
math: false
mermaid: true
---

<!--
meta-description: "Master Go concurrency with goroutines, WaitGroups, and race condition detection. Learn how Go's lightweight concurrency model enables high-performance parallel processing, proper synchronization techniques, and production-ready concurrent patterns for scalable applications."
keywords: "Go goroutines, Go concurrency, goroutine scheduling, sync.WaitGroup, race conditions, Go parallelism, GOMAXPROCS, concurrent programming, Go scheduler, goroutine best practices, preemptive scheduling, cooperative scheduling, goroutine leaks, context cancellation, worker pools"
-->

# <span style="color:#e67e22;">What we will learn in this post?</span>
<ul style='list-style-type: none; padding-left: 0;'>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>üëâ</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Introduction to Goroutines</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>üëâ</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Creating Goroutines</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>üëâ</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Goroutine Scheduling</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>üëâ</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>WaitGroups</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>üëâ</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Race Conditions</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>üëâ</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Goroutine Best Practices</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>üëâ</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Conclusion!</span></li>
</ul>

# <span style="color:#e67e22">Go Routines: Concurrent Magic ü™Ñ</span>

Goroutines are Go's lightweight concurrency primitives that enable you to write highly scalable, concurrent applications with minimal overhead. Unlike traditional operating system threads that consume megabytes of memory, goroutines start with just a few kilobytes and can scale to millions within a single program. This makes Go exceptionally powerful for building high-performance web servers, distributed systems, and real-time data processing pipelines used in production environments at companies like Google, Uber, and Netflix. By mastering goroutines, you'll unlock the ability to build systems that efficiently utilize modern multi-core processors and handle massive concurrent workloads.

## <span style="color:#2980b9">The 'go' Keyword üèÅ</span>

Launching a goroutine is easy! Just prefix a function call with the `go` keyword:

```go
package main

import (
	"fmt"
	"time"
)

func say(s string) {
	for i := 0; i < 5; i++ {
		time.Sleep(100 * time.Millisecond)
		fmt.Println(s)
	}
}

func main() {
	go say("world") // Launch a new goroutine
	say("hello")      // Main goroutine
}
```

This code creates two concurrent execution paths. The `say("world")` function runs in a new goroutine, while `say("hello")` runs in the main one. Because the `say("world")` function call is prefixed with the `go` keyword, it doesn't halt the main goroutine. The program starts the goroutine and immediately continues to the next line of code.

### <span style="color:#8e44ad">Concurrent execution</span>
Because these functions are executing in different goroutines concurrently, both say functions are operating at the same time!

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#ff4f81','primaryTextColor':'#fff','primaryBorderColor':'#c43e3e','lineColor':'#e67e22','secondaryColor':'#6b5bff','tertiaryColor':'#ffd700'}}}%%
sequenceDiagram
    participant Main as üéØ Main Goroutine
    participant New as ‚ö° New Goroutine
    
    Note over Main,New: Concurrent Execution Begins
    Main->>+New: go say("world")
    Main->>Main: say("hello") starts
    
    loop 5 iterations
        New->>New: Sleep 100ms
        New->>New: Print "world"
    end
    
    loop 5 iterations  
        Main->>Main: Sleep 100ms
        Main->>Main: Print "hello"
    end
    
    Note over Main,New: Both complete independently ‚úÖ
    deactivate New
```

*   Goroutines are cheap to create and destroy.
*   Go manages them efficiently, distributing them across available OS threads.

**More Info:** For deeper exploration, check out [Go Concurrency Patterns](https://go.dev/tour/concurrency/1) and [Effective Go on Concurrency](https://go.dev/doc/effective_go#concurrency).

# <span style="color:#e67e22">Go Concurrency with Goroutines üöÄ</span>

Goroutines are Go's fundamental building blocks for concurrent programming, enabling you to write scalable applications that handle thousands or millions of concurrent operations efficiently. In production systems, goroutines power everything from web servers handling millions of requests per second to real-time data streaming platforms processing terabytes of data. Understanding how to create, manage, and coordinate goroutines is essential for building modern, high-performance Go applications that leverage the full power of multi-core processors.

## <span style="color:#2980b9">Creating Goroutines</span>

*   **Anonymous Functions:** Start a goroutine by using the `go` keyword followed by an anonymous function.

    ```go
    go func() {
        // Your code here
        fmt.Println("Hello from a goroutine!")
    }() //Don't forget the trailing parentheses to invoke the anonymous function
    ```

*   **Named Functions:** Similarly, `go` can launch a regular, named function.

    ```go
    func myFunc() {
        fmt.Println("Hello from a named function goroutine!")
    }

    go myFunc()
    ```

## <span style="color:#2980b9">Goroutine Lifecycle ‚è≥</span>

Goroutines have a simple but critical lifecycle that every Go developer must understand for building reliable concurrent systems. When launched, a goroutine runs independently and asynchronously from the main program execution. Unlike traditional threads, goroutines don't block program execution when created, making them perfect for fire-and-forget operations, background processing, and event-driven architectures. However, this asynchronous nature means the main program won't automatically wait for goroutines to complete‚Äîproper synchronization is essential to prevent premature program termination and ensure all concurrent work finishes correctly. This lifecycle model is fundamental to Go's concurrency philosophy and is used extensively in production systems for handling HTTP requests, database queries, and distributed system communication.

## <span style="color:#2980b9">Multiple Goroutines & Closure Capture üëØ</span>

Here's how to launch a bunch:

```go
import "fmt"
import "time"

func main() {
    for i := 0; i < 5; i++ {
        go func(j int) { // Pass 'i' as 'j' to capture the value.
            fmt.Println("Goroutine", j)
        }(i)
    }
    time.Sleep(time.Second) // Give goroutines time to complete.
}
```

*Important:* Be careful when capturing variables in closures. The goroutine might run *after* the loop finishes, and `i` might have changed! Pass the loop variable as an argument to the function to avoid this issue. Always pass loop variables *as parameters* to the goroutine function.

# <span style="color:#e67e22">Go Scheduler: A Quick Dive ü§ø</span>

Go's scheduler is one of the language's most sophisticated components, implementing an advanced M:N scheduling model that multiplexes many goroutines (M) onto a smaller number of operating system threads (N). This design allows Go programs to efficiently manage millions of goroutines with minimal memory overhead and excellent CPU utilization. The scheduler's intelligence enables Go applications to scale seamlessly from single-core to multi-core systems, automatically balancing workloads across available processors. Understanding how the scheduler works helps you write more efficient concurrent code, optimize performance bottlenecks, and design systems that fully leverage modern hardware architectures used in cloud-native applications and microservices.

## <span style="color:#2980b9">GOMAXPROCS and Parallelism ‚öôÔ∏è</span>

`GOMAXPROCS` sets the maximum number of OS threads that can *simultaneously* execute Go code. Increasing it can boost *parallelism* on multi-core machines.

## <span style="color:#2980b9">Goroutine Multiplexing: Sharing the Stage üé≠</span>

Goroutines are *multiplexed* onto OS threads. This means they take turns running. The Go scheduler efficiently switches between them.

### <span style="color:#8e44ad">Scheduling Types: Cooperative vs. Preemptive ü§î</span>

*   **Cooperative Scheduling:** Goroutines *voluntarily* give up control. Older Go versions relied on this.
*   **Preemptive Scheduling:** Go *forces* goroutines to yield, preventing long-running tasks from hogging the CPU. Modern Go uses this, improving fairness.

```mermaid
graph TB
    A["Goroutines Pool (M)"]:::pink --> B["Go Scheduler"]:::purple
    B --> C1["OS Thread 1"]:::teal
    B --> C2["OS Thread 2"]:::teal
    B --> C3["OS Thread N"]:::teal
    
    C1 --> D["CPU Core 1"]:::orange
    C2 --> D
    C3 --> D
    
    B --> E{"Scheduling Decision"}:::gold
    E -- "Cooperative Yield" --> F["Goroutine Pauses"]:::green
    E -- "Preemptive Force" --> G["Goroutine Interrupted"]:::green
    
    classDef pink fill:#ff4f81,stroke:#c43e3e,color:#fff,font-size:16px,stroke-width:3px,rx:14,shadow:6px;
    classDef purple fill:#6b5bff,stroke:#4a3f6b,color:#fff,font-size:16px,stroke-width:3px,rx:14,shadow:6px;
    classDef gold fill:#ffd700,stroke:#d99120,color:#222,font-size:16px,stroke-width:3px,rx:14,shadow:6px;
    classDef teal fill:#00bfae,stroke:#005f99,color:#fff,font-size:16px,stroke-width:3px,rx:14,shadow:6px;
    classDef orange fill:#ff9800,stroke:#f57c00,color:#fff,font-size:16px,stroke-width:3px,rx:14,shadow:6px;
    classDef green fill:#43e97b,stroke:#38f9d7,color:#222,font-size:16px,stroke-width:3px,rx:14,shadow:6px;
    
    linkStyle default stroke:#e67e22,stroke-width:3px;
```

# <span style="color:#e67e22">Coordinating Goroutines with `sync.WaitGroup` ü§ù</span>

The `sync.WaitGroup` is an essential synchronization primitive in Go's standard library, providing a simple yet powerful mechanism for coordinating multiple goroutines and ensuring they complete before program execution continues. In production systems, WaitGroups are used extensively to manage worker pools, coordinate batch processing jobs, and ensure all concurrent operations finish before resources are cleaned up or connections are closed. Mastering WaitGroups is crucial for building reliable concurrent applications, preventing race conditions, and ensuring data integrity in systems ranging from web servers processing multiple requests to distributed data processing pipelines handling millions of events.

## <span style="color:#2980b9">How It Works: Three Key Methods</span>

*   `Add(delta int)`:  Increments the counter.  You usually call this _before_ launching a goroutine to signal that more work is starting.

*   `Done()`:  Decrements the counter.  A goroutine calls this when it's finished its job. *Crucially, this reduces the `WaitGroup` counter*.

*   `Wait()`:  Blocks until the counter is zero.  This is called by the main goroutine (or any goroutine that needs to wait for others) to ensure all tasks are complete before proceeding.

## <span style="color:#2980b9">Practical Example: Waiting for Task Completion ‚úÖ</span>

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

func main() {
	var wg sync.WaitGroup // Creates a waitgroup

	tasks := []string{"Task 1", "Task 2", "Task 3"}

	wg.Add(len(tasks)) // Initialize with number of tasks

	for _, task := range tasks {
		go func(t string) {
			defer wg.Done() // Decrement counter when done
			fmt.Println("Starting", t)
			time.Sleep(time.Second) // Simulate some work
			fmt.Println("Finished", t)
		}(task)
	}

	wg.Wait() // Wait for all tasks to finish
	fmt.Println("All tasks completed!")
}
```

**Explanation:**

1.  We create a `WaitGroup`.
2.  We add the number of tasks to the counter *before* starting the goroutines.
3.  Each goroutine calls `Done()` when it finishes. Using `defer` ensures this happens even if the goroutine panics.
4.  `Wait()` blocks until all goroutines have called `Done()` enough times to bring the counter back to zero.

*Resource link for more info on the topic [Official Go Documentation](https://pkg.go.dev/sync#WaitGroup)*

## <span style="color:#2980b9">Real-World Example: Concurrent Image Processing üñºÔ∏è</span>

Here's a practical example of using WaitGroups in a production scenario‚Äîprocessing multiple images concurrently:

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

// Simulates image processing (resize, compress, apply filters)
func processImage(imageID int, wg *sync.WaitGroup) {
	defer wg.Done()
	
	fmt.Printf("üîÑ Processing image %d...\n", imageID)
	
	// Simulate CPU-intensive work
	time.Sleep(time.Duration(100+imageID*50) * time.Millisecond)
	
	fmt.Printf("‚úÖ Image %d processed successfully\n", imageID)
}

func main() {
	images := []int{1, 2, 3, 4, 5, 6, 7, 8}
	var wg sync.WaitGroup
	
	fmt.Println("ÔøΩ Starting concurrent image processing pipeline...")
	
	wg.Add(len(images))
	
	for _, imgID := range images {
		go processImage(imgID, &wg)
	}
	
	wg.Wait()
	fmt.Println("\nüéâ All images processed! Ready for deployment.")
}
```

This pattern is used in production systems for:
- Thumbnail generation for media platforms
- Batch data transformation in ETL pipelines
- Concurrent API calls to microservices
- Parallel database queries


# <span style="color:#e67e22">Race Conditions in Go: Unveiling Concurrency Hazards üö¶</span>

Race conditions represent one of the most dangerous and subtle bugs in concurrent programming, occurring when multiple goroutines access shared memory simultaneously without proper synchronization. These bugs are particularly insidious because they often don't manifest consistently‚Äîthey may appear only under specific timing conditions or heavy load, making them extremely difficult to debug in production. In real-world systems, race conditions can lead to data corruption, security vulnerabilities, financial losses, and system crashes. Understanding how to detect, prevent, and fix race conditions is absolutely critical for building production-grade Go applications, especially in systems handling sensitive data, financial transactions, or high-throughput operations where correctness is non-negotiable.

## <span style="color:#2980b9">The Peril of Unsynchronized Access üò®</span>

When goroutines read and write to the same memory location simultaneously, the order of operations becomes non-deterministic.

*   **Example:** Let's say we have a counter incremented by multiple goroutines.

    ```go
    package main

    import (
    	"fmt"
    	"sync"
    )

    var counter int = 0
    var wg sync.WaitGroup

    func increment() {
    	defer wg.Done()
    	for i := 0; i < 1000; i++ {
    		counter++ // Data race!
    	}
    }

    func main() {
    	wg.Add(2)
    	go increment()
    	go increment()
    	wg.Wait()
    	fmt.Println("Counter:", counter) // Usually not 2000
    }
    ```

*   Without synchronization, `counter++` (read-modify-write) can be interrupted, leading to lost updates.

## <span style="color:#2980b9">Detecting Races with 'go run -race' üïµÔ∏è‚Äç‚ôÄÔ∏è</span>

Go provides a powerful tool for detecting race conditions: the `-race` flag.

*   Run your code with `go run -race main.go`. If a race is detected, the tool will print a detailed report, pointing you to the problematic code.

## <span style="color:#2980b9">Why Race Detection Matters Urgently üö®</span>

*   Race conditions can cause subtle and difficult-to-debug errors.
*   They might not appear consistently, making them hard to reproduce.
*   The `-race` flag helps you catch these issues early, preventing potential bugs in production.
*   Using `-race` in CI/CD is highly recommended.

For more details on synchronization techniques to avoid race conditions, see resources like:
*   [Effective Go](https://go.dev/doc/effective_go#concurrency)
*   [Go Concurrency Patterns: Context](https://go.dev/tour/concurrency/1)

## <span style="color:#2980b9">Real-World Example: Bank Account Race Condition üí∞</span>

Here's a practical example showing how race conditions can cause financial data corruption:

```go
package main

import (
	"fmt"
	"sync"
)

type BankAccount struct {
	balance int
	mu      sync.Mutex // Protects balance
}

// Unsafe withdrawal - demonstrates race condition
func (acc *BankAccount) WithdrawUnsafe(amount int) {
	if acc.balance >= amount {
		// Race condition: another goroutine might withdraw here
		acc.balance -= amount
	}
}

// Safe withdrawal - uses mutex for synchronization
func (acc *BankAccount) WithdrawSafe(amount int) {
	acc.mu.Lock()
	defer acc.mu.Unlock()
	
	if acc.balance >= amount {
		acc.balance -= amount
		fmt.Printf("‚úÖ Withdrew $%d, new balance: $%d\n", amount, acc.balance)
	} else {
		fmt.Printf("‚ùå Insufficient funds for $%d withdrawal\n", amount)
	}
}

func main() {
	account := &BankAccount{balance: 1000}
	var wg sync.WaitGroup
	
	// Simulate 10 concurrent withdrawals
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()
			account.WithdrawSafe(150) // Use safe version
		}(i)
	}
	
	wg.Wait()
	fmt.Printf("\nüí∞ Final balance: $%d\n", account.balance)
}
```

Without proper synchronization, this could lead to negative balances or lost transactions‚Äîcritical bugs in financial systems!


# <span style="color:#e67e22">Goroutine Management: A Friendly Guide üöÄ</span>

Proper goroutine management is the difference between a robust, scalable production system and a memory-leaking, resource-exhausting disaster. In real-world applications, unmanaged goroutines can accumulate over time (goroutine leaks), consuming memory and eventually causing application crashes or performance degradation. Production systems at scale‚Äîhandling millions of requests, processing streaming data, or managing long-lived connections‚Äîmust implement rigorous goroutine lifecycle management, including graceful shutdown, timeout handling, and resource cleanup. These patterns are essential for building cloud-native applications, microservices, and distributed systems that can reliably operate 24/7 under varying load conditions.

## <span style="color:#2980b9">Keeping Things Clean & Tidy üßπ</span>

*   **Avoid Goroutine Leaks:** Make sure *every* goroutine can exit. If a goroutine waits forever (e.g., on a channel), it's a leak. Use `select` with a `default` case or a timeout.

    ```go
    select {
    case msg := <-ch:
        fmt.Println("Received:", msg)
    case <-time.After(time.Second):
        fmt.Println("Timeout! Exiting.")
        return // Important to exit the goroutine
    }
    ```

*   **Proper Shutdown:** Use a `context.Context` for canceling goroutines. When the context is canceled, your goroutines should exit gracefully. See [Context documentation](https://pkg.go.dev/context) for details.

    ```go
    ctx, cancel := context.WithCancel(context.Background())
    go myWorker(ctx)

    // Later, to signal shutdown:
    cancel()
    ```

*   **Limit Goroutines:** Don't create *unlimited* goroutines. Use a worker pool. You can use `sync.WaitGroup` to manage a pool of workers. See [Worker Pool Pattern](https://gobyexample.com/worker-pools)

    ```go
    var wg sync.WaitGroup
    numWorkers := 10

    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            // Your worker code here
        }()
    }

    wg.Wait() // Wait for all workers to finish
    ```

*   **Shutdown Signals:** Use channels to communicate shutdown signals to goroutines.

    ```go
    quit := make(chan struct{})
    go func() {
        for {
            select {
            case <-quit:
                fmt.Println("Exiting goroutine")
                return
            default:
                // Do some work
            }
        }
    }()

    // Later, to signal shutdown:
    close(quit)
    ```

## <span style="color:#2980b9">Example Flowchart üó∫Ô∏è</span>

```mermaid
%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#ff4f81','primaryTextColor':'#fff','primaryBorderColor':'#c43e3e','lineColor':'#e67e22','secondaryColor':'#6b5bff','tertiaryColor':'#ffd700'}}}%%
sequenceDiagram
    participant Main as üéØ Main Process
    participant Worker as ‚öôÔ∏è Goroutine Worker
    participant Signal as üö¶ Shutdown Signal
    
    Note over Main,Worker: Goroutine Lifecycle Management
    
    Main->>+Worker: Start goroutine
    
    loop Process work items
        Worker->>Worker: Check for shutdown signal
        alt No signal
            Worker->>Worker: Do work
        else Shutdown signal received
            Worker->>Signal: Acknowledge shutdown
            Worker->>Main: Exit gracefully ‚úÖ
        end
    end
    
    Main->>Signal: Send shutdown (context.Cancel or close channel)
    Signal-->>Worker: Propagate signal
    Worker-->>-Main: Goroutine terminated
    
    Note over Main,Worker: Clean shutdown completed üéâ
```

By following these practices, you can write Go programs that are reliable, efficient, and easy to manage! üòä

## <span style="color:#2980b9">Real-World Example: HTTP Server with Graceful Shutdown üåê</span>

Here's how production web servers implement proper goroutine management with graceful shutdown:

```go
package main

import (
	"context"
	"fmt"
	"net/http"
	"os"
	"os/signal"
	"sync"
	"syscall"
	"time"
)

// Worker pool for handling background tasks
func startWorkerPool(ctx context.Context, wg *sync.WaitGroup, numWorkers int) {
	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			fmt.Printf("üü¢ Worker %d started\n", workerID)
			
			for {
				select {
				case <-ctx.Done():
					fmt.Printf("üî¥ Worker %d shutting down gracefully\n", workerID)
					return
				case <-time.After(2 * time.Second):
					fmt.Printf("‚öôÔ∏è  Worker %d processing task...\n", workerID)
				}
			}
		}(i)
	}
}

func main() {
	// Create cancellable context for graceful shutdown
	ctx, cancel := context.WithCancel(context.Background())
	var wg sync.WaitGroup
	
	// Start HTTP server
	server := &http.Server{Addr: ":8080"}
	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		fmt.Fprintf(w, "Server is running! üöÄ")
	})
	
	go func() {
		fmt.Println("üåê HTTP Server listening on :8080")
		if err := server.ListenAndServe(); err != http.ErrServerClosed {
			fmt.Printf("‚ùå Server error: %v\n", err)
		}
	}()
	
	// Start worker pool
	startWorkerPool(ctx, &wg, 3)
	
	// Wait for interrupt signal (Ctrl+C)
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
	<-sigChan
	
	fmt.Println("\nüõë Shutdown signal received. Initiating graceful shutdown...")
	
	// Cancel context to signal all goroutines
	cancel()
	
	// Shutdown HTTP server with timeout
	shutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer shutdownCancel()
	
	if err := server.Shutdown(shutdownCtx); err != nil {
		fmt.Printf("‚ùå Server shutdown error: %v\n", err)
	}
	
	// Wait for all workers to finish
	wg.Wait()
	fmt.Println("‚úÖ All goroutines stopped. Clean shutdown completed!")
}
```

This pattern is used in production for:
- Microservices with graceful shutdown on deployment
- API gateways handling thousands of concurrent connections
- Background job processors with clean termination
- Stream processing systems with checkpoint management


Okay, here are a few options for your conclusion statement, each formatted as requested and under 150 words:



<h1><span style='color:#e67e22'>Conclusion</span></h1>

And that's a wrap! üéâ You've now mastered the fundamentals of Go's powerful concurrency model‚Äîfrom launching lightweight goroutines to coordinating them with WaitGroups, detecting race conditions, and implementing graceful shutdown patterns used in production systems. These skills will enable you to build highly scalable, concurrent applications that efficiently leverage modern multi-core processors. We'd love to hear about your experiences with Go concurrency! Have you encountered interesting race conditions? Built worker pools? Share your thoughts, questions, or alternative approaches in the comments below! üí¨ What will you build with goroutines? ÔøΩ



