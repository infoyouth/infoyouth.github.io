Error: API request failed with error: 401 Client Error: Unauthorized for url: https://openrouter.ai/api/v1/chat/completions

# <span style="color:#e67e22;">What we will learn in this post?</span>
<ul style='list-style-type: none; padding-left: 0;'>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>ğŸ‘‰</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Worker Pool Pattern</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>ğŸ‘‰</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Fan-Out and Fan-In Patterns</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>ğŸ‘‰</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Pipeline Pattern</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>ğŸ‘‰</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Select Statement Patterns</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>ğŸ‘‰</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Rate Limiting and Throttling</span></li>
<li><span style='color: #2980b9; font-size: 20px; font-weight: bold;'>ğŸ‘‰</span> <span style='color: #2ecc71; font-size: 18px; font-weight: bold;'>Semaphore Pattern</span></li>
</ul>

# <span style="color:#e67e22">Understanding the Worker Pool Pattern ğŸ› ï¸</span>

The **worker pool pattern** is a great way to manage tasks in a program. It helps you control how many tasks run at the same time, making your application efficient and responsive. Letâ€™s break it down!

## <span style="color:#2980b9">What is a Worker Pool? ğŸ¤”</span>

A worker pool consists of:
- **Workers**: These are the threads or processes that do the work.
- **Job Queue**: This is where tasks wait to be processed.

### <span style="color:#8e44ad">How It Works ğŸ”„</span>

1. **Job Distribution**: When a task is added to the queue, a worker picks it up and starts working on it.
2. **Concurrency Control**: You can limit the number of workers to control how many tasks run at once.
3. **Graceful Shutdown**: Workers can finish their tasks before stopping, ensuring no work is lost.
4. **Backpressure Handling**: If the queue gets too full, you can pause adding new tasks until some are completed.

### <span style="color:#8e44ad">Example Implementation ğŸ’»</span>

Hereâ€™s a simple example in Python:

```python
import queue
import threading
import time

def worker(job_queue):
    while True:
        job = job_queue.get()
        if job is None:
            break
        print(f"Processing {job}")
        time.sleep(1)  # Simulate work
        job_queue.task_done()

job_queue = queue.Queue()
num_workers = 4

# Start workers
threads = []
for _ in range(num_workers):
    t = threading.Thread(target=worker, args=(job_queue,))
    t.start()
    threads.append(t)

# Add jobs
for job in range(10):
    job_queue.put(job)

# Wait for all jobs to finish
job_queue.join()

# Stop workers
for _ in range(num_workers):
    job_queue.put(None)
for t in threads:
    t.join()
```

### <span style="color:#2980b9">Key Benefits ğŸŒŸ</span>

- **Efficiency**: Makes better use of resources.
- **Scalability**: Easy to add more workers.
- **Control**: Manage how tasks are processed.

For more details, check out [this resource](https://en.wikipedia.org/wiki/Thread_pool).

Happy coding! ğŸ˜Š

# <span style="color:#e67e22">Understanding Fan-Out and Fan-In Patterns</span>

## <span style="color:#2980b9">What is Fan-Out? ğŸŒŸ</span>

The **fan-out pattern** allows you to distribute work across multiple goroutines. This is useful for tasks that can be done in parallel.

### Example of Fan-Out

```go
package main

import (
    "fmt"
    "sync"
)

func worker(id int, wg *sync.WaitGroup) {
    defer wg.Done()
    fmt.Printf("Worker %d is processing\n", id)
}

func main() {
    var wg sync.WaitGroup
    for i := 1; i <= 5; i++ {
        wg.Add(1)
        go worker(i, &wg)
    }
    wg.Wait()
}
```

## <span style="color:#2980b9">What is Fan-In? ğŸ“¥</span>

The **fan-in pattern** collects results from multiple goroutines into a single channel. This helps in aggregating results efficiently.

### Example of Fan-In

```go
package main

import (
    "fmt"
)

func square(n int, ch chan int) {
    ch <- n * n
}

func main() {
    ch := make(chan int)
    for i := 1; i <= 5; i++ {
        go square(i, ch)
    }
    
    for i := 1; i <= 5; i++ {
        fmt.Println(<-ch)
    }
}
```

## <span style="color:#2980b9">Combining Fan-Out and Fan-In ğŸ”„</span>

You can combine both patterns to create a pipeline for parallel processing.

### Example of Combined Patterns

```go
package main

import (
    "fmt"
    "sync"
)

func worker(id int, ch chan<- int, wg *sync.WaitGroup) {
    defer wg.Done()
    ch <- id * id
}

func main() {
    var wg sync.WaitGroup
    ch := make(chan int, 5)

    for i := 1; i <= 5; i++ {
        wg.Add(1)
        go worker(i, ch, &wg)
    }

    go func() {
        wg.Wait()
        close(ch)
    }()

    for result := range ch {
        fmt.Println(result)
    }
}
```

### Resources for More Info
- [Go Concurrency Patterns](https://blog.golang.org/concurrency-patterns)
- [Goroutines and Channels](https://golang.org/doc/effective_go.html#goroutines)

By using these patterns, you can efficiently manage concurrent tasks in Go! Happy coding! ğŸ‰

# <span style="color:#e67e22">Building Concurrent Pipelines with Stages</span> ğŸš€

Creating a **data processing pipeline** can be fun and efficient! Letâ€™s break it down into simple parts: stages, channels, and how they all work together.

## <span style="color:#2980b9">What are Stages and Channels?</span> ğŸŒŸ

- **Stages**: Think of these as steps in a recipe. Each stage does a specific job, like filtering or transforming data.
- **Channels**: These are like pipes that connect the stages. They carry data from one stage to the next.

### <span style="color:#8e44ad">The Generator Pattern</span> ğŸ”„

This pattern helps us create data in a way that can be processed one piece at a time. Itâ€™s like a conveyor belt in a factory!

### <span style="color:#8e44ad">Processing Stages and Sink Stage</span> ğŸ› ï¸

- **Processing Stages**: Each stage processes data and sends it to the next stage.
- **Sink Stage**: This is the final stage where we collect the results.

## <span style="color:#2980b9">Example Implementation</span> ğŸ’»

Hereâ€™s a simple example in Python:

```python
import asyncio

async def stage_one(channel):
    for i in range(5):
        await channel.put(i)
    await channel.put(None)  # Signal completion

async def stage_two(channel_in, channel_out):
    while True:
        item = await channel_in.get()
        if item is None:
            await channel_out.put(None)  # Signal completion
            break
        await channel_out.put(item * 2)

async def sink(channel):
    while True:
        item = await channel.get()
        if item is None:
            break
        print(f"Processed item: {item}")

async def main():
    channel1 = asyncio.Queue()
    channel2 = asyncio.Queue()

    await asyncio.gather(
        stage_one(channel1),
        stage_two(channel1, channel2),
        sink(channel2)
    )

asyncio.run(main())
```

### <span style="color:#2980b9">Key Points</span> ğŸ“Œ

- Use **async** functions for non-blocking operations.
- Close channels properly to avoid hanging processes.
- Each stage can be independently developed and tested.

For more details, check out [Python's asyncio documentation](https://docs.python.org/3/library/asyncio.html).

Happy coding! ğŸ‰

# <span style="color:#e67e22">Advanced Select Patterns in Go</span>

## <span style="color:#2980b9">Understanding Select in Go</span>

The `select` statement in Go is a powerful tool for handling multiple channel operations. Here are some advanced patterns to enhance your Go programming skills! ğŸš€

### <span style="color:#8e44ad">1. Timeout Handling â³</span>

You can use a `time.After` channel to implement timeouts. If an operation takes too long, you can handle it gracefully.

```go
select {
case result := <-ch:
    // Handle result
case <-time.After(2 * time.Second):
    // Handle timeout
}
```

### <span style="color:#8e44ad">2. Default Case for Non-blocking Operations ğŸš¦</span>

Using a `default` case allows you to perform non-blocking operations.

```go
select {
case result := <-ch:
    // Handle result
default:
    // Do something else if no data is ready
}
```

### <span style="color:#8e44ad">3. Nil Channel Tricks ğŸŒ€</span>

You can use a nil channel to skip a case in `select`.

```go
var ch chan int
select {
case <-ch: // This case is skipped
}
```

### <span style="color:#8e44ad">4. Select with Done Channel for Cancellation âŒ</span>

You can use a `done` channel to signal cancellation.

```go
done := make(chan struct{})
select {
case <-done:
    // Handle cancellation
case result := <-ch:
    // Handle result
}
```

### <span style="color:#8e44ad">5. Combining Multiple Channel Operations ğŸ”—</span>

You can combine multiple channels in a single `select`.

```go
select {
case result1 := <-ch1:
    // Handle result from ch1
case result2 := <-ch2:
    // Handle result from ch2
}
```

## <span style="color:#2980b9">Resources for More Info ğŸ“š</span>

- [Go by Example: Select](https://gobyexample.com/select)
- [Effective Go](https://golang.org/doc/effective_go.html#concurrency)

Feel free to explore these patterns to make your Go applications more robust and efficient! Happy coding! ğŸ˜Š

# <span style="color:#e67e22">Implementing Rate Limiting in Go</span> ğŸš¦

Rate limiting is essential for controlling how many requests your API can handle. It helps prevent abuse and ensures fair usage. Let's explore how to implement it in Go using the **token bucket algorithm** and the `golang.org/x/time/rate` package.

## <span style="color:#2980b9">What is Rate Limiting?</span>

Rate limiting restricts the number of requests a user can make in a given time frame. This is crucial for:

- **Preventing server overload**
- **Ensuring fair access for all users**
- **Protecting against abuse**

### <span style="color:#8e44ad">Using the Token Bucket Algorithm</span>

The token bucket algorithm allows for burst traffic while maintaining an average rate. Hereâ€™s how it works:

- Tokens are added to a bucket at a fixed rate.
- Each request consumes a token.
- If the bucket is empty, requests are denied until tokens are available.

### <span style="color:#8e44ad">Implementation Example</span>

Hereâ€™s a simple example using Go:

```go
package main

import (
    "golang.org/x/time/rate"
    "time"
    "fmt"
)

func main() {
    limiter := rate.NewLimiter(1, 5) // 1 request per second, burst of 5

    for i := 0; i < 10; i++ {
        if err := limiter.Wait(context.Background()); err != nil {
            fmt.Println("Rate limit exceeded:", err)
            continue
        }
        fmt.Println("API request", i)
    }
}
```

### <span style="color:#2980b9">Handling Burst Traffic</span>

With the above setup, you can handle bursts of up to 5 requests at once, while maintaining a steady rate of 1 request per second.

### <span style="color:#8e44ad">Resources</span>

For more details, check out the [Go Rate Limiting Documentation](https://pkg.go.dev/golang.org/x/time/rate).

Implementing rate limiting is a great way to enhance your API's reliability and user experience! ğŸŒŸ

# <span style="color:#e67e22">Using Semaphores in Go</span> ğŸš¦

Semaphores help control access to resources in concurrent programming. Letâ€™s explore how to use them in Go!

## <span style="color:#2980b9">What is a Semaphore?</span>

A semaphore is a signaling mechanism that limits the number of goroutines accessing a resource. 

### <span style="color:#8e44ad">Buffered Channels as Semaphores</span>

You can use buffered channels to create a simple semaphore:

```go
sem := make(chan struct{}, 3) // Limit to 3 concurrent accesses

for i := 0; i < 10; i++ {
    sem <- struct{}{} // Acquire
    go func(i int) {
        defer func() { <-sem }() // Release
        // Access resource
    }(i)
}
```

### <span style="color:#8e44ad">Weighted Semaphores</span>

Weighted semaphores allow different weights for goroutines. You can implement this with a custom structure.

### <span style="color:#8e44ad">Using `golang.org/x/sync/semaphore`</span>

This package provides a robust semaphore implementation. Hereâ€™s how to use it:

```go
import "golang.org/x/sync/semaphore"

sem := semaphore.NewWeighted(3) // Limit to 3

for i := 0; i < 10; i++ {
    if err := sem.Acquire(ctx, 1); err != nil {
        // Handle error
    }
    go func(i int) {
        defer sem.Release(1) // Release
        // Access resource
    }(i)
}
```

## <span style="color:#2980b9">Key Points</span>

- **Control Access**: Semaphores limit concurrent access to resources.
- **Buffered Channels**: Simple way to implement semaphores.
- **Weighted Semaphores**: Allow different access levels.
- **`golang.org/x/sync/semaphore`**: A powerful package for semaphores.

For more details, check out the [Go documentation](https://golang.org/doc/). Happy coding! ğŸ‰

